{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalar e Importar Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar e importar as dependências necessárias para o projeto, incluindo PyTorch, Torchvision e Torchaudio.\n",
    "# Aqui estamos utilizando o comando pip para instalar as bibliotecas torch, torchvision e torchaudio.\n",
    "# Essas bibliotecas são essenciais para trabalhar com redes neurais profundas e visão computacional.\n",
    "# O parâmetro --index-url especifica o índice de onde os pacotes serão baixados.\n",
    "# Caso você esteja utilizando uma GPU diferente, pode ser necessário alterar a URL para a versão correta do CUDA.\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Se necessárias para o projeto.\n",
    "# Clonar o repositório YOLOv5 do GitHub.\n",
    "# O YOLOv5 é uma das arquiteturas mais populares para detecção de objetos em tempo real.\n",
    "# Clonando o repositório, teremos acesso ao código e aos modelos pré-treinados.\n",
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "# Se necessárias para o projeto.\n",
    "# Instalar as dependências listadas no arquivo requirements.txt do repositório YOLOv5.\n",
    "# Essas dependências incluem bibliotecas adicionais necessárias para o funcionamento do YOLOv5.\n",
    "# O comando cd yolov5 navega até o diretório clonado e pip install -r requirements.txt instala as dependências.\n",
    "!cd yolov5 & pip install -r requirements.txt\n",
    "\n",
    "# Importar as bibliotecas necessárias para o projeto.\n",
    "# torch: Biblioteca principal do PyTorch para criação e treinamento de modelos de aprendizado profundo.\n",
    "# matplotlib.pyplot: Biblioteca para criação de gráficos e visualização de dados.\n",
    "# numpy: Biblioteca para manipulação de arrays e operações matemáticas.\n",
    "# cv2: Biblioteca OpenCV para processamento de imagens e vídeos.\n",
    "# os: Biblioteca para interagir com o sistema operacional, como manipulação de arquivos e diretórios.\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas necessárias para o projeto.\n",
    "# torch: Biblioteca principal do PyTorch para criação e treinamento de modelos de aprendizado profundo.\n",
    "# matplotlib.pyplot: Biblioteca para criação de gráficos e visualização de dados.\n",
    "# numpy: Biblioteca para manipulação de arrays e operações matemáticas.\n",
    "# cv2: Biblioteca OpenCV para processamento de imagens e vídeos.\n",
    "# os: Biblioteca para interagir com o sistema operacional, como manipulação de arquivos e diretórios.\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar o Modelo do Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Treinar o modelo YOLOv5 do zero usando um conjunto de dados personalizado.\n",
    "# Aqui estamos utilizando o comando para treinar o modelo YOLOv5.\n",
    "# O parâmetro --img especifica o tamanho das imagens de entrada.\n",
    "# O parâmetro --batch define o tamanho do lote para o treinamento.\n",
    "# O parâmetro --epochs define o número de épocas para o treinamento.\n",
    "# O parâmetro --data especifica o arquivo de configuração do conjunto de dados.\n",
    "# O parâmetro --workers define o número de trabalhadores para carregar os dados.\n",
    "# Você pode ajustar esses parâmetros conforme necessário para melhorar o desempenho ou adaptar às suas necessidades.\n",
    "!python train.py --img 640 --batch-size -1 --epochs 150 --data ../dataset.yml --weights yolov5s.pt --workers 8 --patience 30 --cache ram --image-weights --project Drowsiness_Detection --name Optimized_Run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Modelo Personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregar o modelo YOLOv5 personalizado treinado a partir do caminho especificado.\n",
    "# Aqui estamos utilizando a função torch.hub.load para carregar um modelo YOLOv5 personalizado.\n",
    "# O parâmetro 'ultralytics/yolov5' especifica o repositório do modelo.\n",
    "# O parâmetro 'custom' indica que estamos carregando um modelo personalizado.\n",
    "# O parâmetro path define o caminho para o arquivo de pesos do modelo treinado.\n",
    "# O parâmetro force_reload=True força o recarregamento do modelo, garantindo que estamos utilizando a versão mais recente.\n",
    "# Caso você tenha treinado o modelo em um caminho diferente, altere o valor do parâmetro path para o caminho correto.\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "# Substitui temporariamente PosixPath por WindowsPath\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Carrega o modelo sem erro\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='runs/train/exp3/weights/last.pt', force_reload=True)\n",
    "\n",
    "# Restaura PosixPath para evitar problemas futuros\n",
    "pathlib.PosixPath = temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Imagem de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar uma imagem de teste para realizar a detecção de objetos.\n",
    "# Aqui estamos utilizando a função os.path.join para construir o caminho completo da imagem de teste.\n",
    "# A imagem será carregada a partir do diretório 'data/test/images'.\n",
    "# Você pode substituir o nome do arquivo de imagem pelo nome da sua imagem de teste.\n",
    "# Certifique-se de que a imagem esteja no diretório especificado ou ajuste o caminho conforme necessário.\n",
    "img = os.path.join('img_test.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obter Resultados do Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os resultados da detecção de objetos na imagem de teste usando o modelo carregado.\n",
    "# Aqui estamos utilizando o modelo YOLOv5 carregado para realizar a detecção de objetos na imagem de teste.\n",
    "# A função model(img) processa a imagem e retorna os resultados da detecção.\n",
    "# Você pode ajustar os parâmetros do modelo ou da imagem conforme necessário para melhorar a precisão ou o desempenho.\n",
    "results = model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exibir Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os resultados da detecção de objetos na imagem de teste usando Matplotlib.\n",
    "# Aqui estamos utilizando a função %matplotlib inline para garantir que os gráficos sejam exibidos diretamente no notebook.\n",
    "# A função plt.imshow é utilizada para exibir a imagem com os resultados da detecção.\n",
    "# A função np.squeeze é utilizada para remover dimensões de tamanho 1 do array, se necessário.\n",
    "# A função results.render() retorna a imagem com as detecções desenhadas sobre ela.\n",
    "# A função plt.show() exibe a imagem no notebook.\n",
    "%matplotlib inline \n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicializar e Processar Vídeo da Câmera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar a câmera e processar o vídeo em tempo real para detecção de sonolência usando o modelo YOLOv5.\n",
    "# Aqui estamos utilizando a biblioteca OpenCV para capturar o vídeo da câmera.\n",
    "# O índice 1 no cv2.VideoCapture(1) pode ser alterado para 0 ou outro número, dependendo da sua configuração de câmera.\n",
    "# O loop while cap.isOpened() continua enquanto a câmera estiver aberta.\n",
    "# A função cap.read() captura um quadro do vídeo. Se não conseguir capturar, imprime uma mensagem de erro e sai do loop.\n",
    "# O quadro capturado é rotacionado 90 graus no sentido horário usando cv2.rotate.\n",
    "# O modelo YOLOv5 é utilizado para processar o quadro rotacionado e detectar objetos.\n",
    "# A função results.render() desenha as detecções no quadro.\n",
    "# O quadro processado é exibido em uma janela usando cv2.imshow.\n",
    "# O loop é interrompido se a tecla 'q' for pressionada.\n",
    "# No final, a câmera é liberada e todas as janelas OpenCV são fechadas.\n",
    "\n",
    "cap = cv2.VideoCapture(2)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Erro ao capturar o quadro.\")\n",
    "        break\n",
    "\n",
    "    rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    results = model(rotated_frame)\n",
    "    rendered_frame = np.squeeze(results.render())\n",
    "    cv2.imshow('YOLO', rendered_frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
